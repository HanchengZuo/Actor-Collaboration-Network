{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bc420e-f0c3-4c09-8045-504afe9c9605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching genres: 100%|███████████████████████████████████████████████████████| 554884/554884 [7:40:10<00:00, 20.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total deleted rows: 109210\n",
      "Remaining rows: 445674\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class MovieDataFetcher:\n",
    "    \"\"\"\n",
    "    A class to fetch movie data from an external API.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def get_movie_genres(self, movie_id):\n",
    "        \"\"\"\n",
    "        Retrieves the genres of a movie by its ID.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            url = f\"https://api.themoviedb.org/3/movie/{movie_id}\"\n",
    "            params = {\"api_key\": self.api_key, \"language\": \"en-US\"}\n",
    "            movie_data = self._make_request(url, params)\n",
    "    \n",
    "            if movie_data is None:\n",
    "                return movie_id, None\n",
    "    \n",
    "            movie_genres = movie_data.get(\"genres\")\n",
    "            genres = [genre['name'] for genre in movie_genres] if movie_genres else []\n",
    "    \n",
    "            return movie_id, genres\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching movie ID {movie_id}: {e}\")\n",
    "            return movie_id, None\n",
    "\n",
    "    def _make_request(self, url, params):\n",
    "        \"\"\"\n",
    "        Makes a GET request to the specified URL with given parameters.\n",
    "        \"\"\"\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        return response.json()\n",
    "        \n",
    "    @staticmethod\n",
    "    def write_deleted_id_to_file(movie_id, file_name='deleted_movie_ids.txt'):\n",
    "        \"\"\"\n",
    "        Writes a deleted movie ID to a specified file.\n",
    "        \"\"\"\n",
    "        with open(file_name, 'a') as file:\n",
    "            file.write(f\"{movie_id}\\n\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('movie_details.csv')\n",
    "\n",
    "# Initialize movie data fetcher\n",
    "api_key = \"6c72b652e1a5b56a3ef1c5989cf1d128\" \n",
    "fetcher = MovieDataFetcher(api_key)\n",
    "\n",
    "# Parallel fetching movie genres\n",
    "movie_ids = df['Movie ID'].tolist()\n",
    "with ThreadPoolExecutor() as executor: \n",
    "    future_to_movie_id = {executor.submit(fetcher.get_movie_genres, movie_id): movie_id for movie_id in movie_ids}\n",
    "    \n",
    "    for future in tqdm(as_completed(future_to_movie_id), total=len(movie_ids), desc=\"Fetching genres\"):\n",
    "        movie_id, genres = future.result()\n",
    "        if not genres:\n",
    "            df = df[df['Movie ID'] != movie_id]\n",
    "            MovieDataFetcher.write_deleted_id_to_file(movie_id)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_movie_details.csv', index=False)\n",
    "\n",
    "# Count the deleted and remaining rows\n",
    "final_count = len(df)\n",
    "deleted_count = len(movie_ids) - final_count\n",
    "\n",
    "print(f\"Total deleted rows: {deleted_count}\")\n",
    "print(f\"Remaining rows: {final_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3bf2a1-c57d-4ed3-abbe-ad340b62a55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 273 rows with three or more duplicate cast names.\n",
      "Remaining rows in the dataset: 445401.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cleaned_movie_details = pd.read_csv('../cleaned_movie_details.csv')\n",
    "\n",
    "def has_three_or_more_duplicates(cast_list):\n",
    "    name_counts = {}\n",
    "    for name in cast_list:\n",
    "        if name in name_counts:\n",
    "            name_counts[name] += 1\n",
    "            if name_counts[name] >= 3:\n",
    "                return True\n",
    "        else:\n",
    "            name_counts[name] = 1\n",
    "    return False\n",
    "\n",
    "cleaned_movie_details['Cast'] = cleaned_movie_details['Cast'].apply(eval)\n",
    "\n",
    "initial_count = len(cleaned_movie_details)\n",
    "cleaned_movie_details = cleaned_movie_details[~cleaned_movie_details['Cast'].apply(has_three_or_more_duplicates)]\n",
    "final_count = len(cleaned_movie_details)\n",
    "\n",
    "deleted_rows = initial_count - final_count\n",
    "\n",
    "print(f\"Deleted {deleted_rows} rows with three or more duplicate cast names.\")\n",
    "print(f\"Remaining rows in the dataset: {final_count}.\")\n",
    "\n",
    "cleaned_movie_details.to_csv('cleaned_movie_details.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba30dfb-6e75-4cc8-971b-6cfa3e6ff05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 389161/389161 [01:33<00:00, 4154.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cleaned and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from processing_functions import process_row  # Import from the separate script\n",
    "\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv('../cleaned_movie_details.csv')\n",
    "\n",
    "    # Convert 'Release Date' to datetime\n",
    "    df['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\n",
    "\n",
    "    # Filter out movies released before the 1960s\n",
    "    df = df[df['Release Date'].dt.year >= 1960]\n",
    "\n",
    "    # Parallel processing\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        # Process each row in parallel\n",
    "        results = list(tqdm(executor.map(process_row, df.to_dict('records')), total=len(df), desc=\"Processing\"))\n",
    "\n",
    "    # Convert the results back to a DataFrame\n",
    "    df_processed = pd.DataFrame(results)\n",
    "\n",
    "    # Save the cleaned dataset\n",
    "    df_processed.to_csv('cleaned_movie_details.csv', index=False)\n",
    "\n",
    "    print(\"Dataset cleaned and saved successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f4d73a-ba6d-4010-b631-f8b56aef768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 389161/389161 [06:05<00:00, 1063.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed: 10528\n",
      "Rows remaining: 378633\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('../cleaned_movie_details.csv')\n",
    "\n",
    "def is_valid_name(name):\n",
    "    \n",
    "    invalid_chars = '1234567890!@#$%^&*()_+=[]{}|\\\\;:\"<>,/?'\n",
    "    return not any(char in name for char in invalid_chars)\n",
    "\n",
    "\n",
    "def format_name(name):\n",
    "    return ' '.join(name.strip().split())\n",
    "\n",
    "rows_removed = 0\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    \n",
    "    directors = [format_name(name) for name in eval(row['Directors'])]\n",
    "    cast = [format_name(name) for name in eval(row['Cast'])]\n",
    "\n",
    "    df.at[index, 'Directors'] = str(directors)\n",
    "    df.at[index, 'Cast'] = str(cast)\n",
    "    \n",
    "    if not all(is_valid_name(name) for name in directors + cast):\n",
    "        df.drop(index, inplace=True)\n",
    "        rows_removed += 1\n",
    "\n",
    "df.to_csv('cleaned_movie_details.csv', index=False)\n",
    "\n",
    "rows_remaining = df.shape[0]\n",
    "print(f\"Rows removed: {rows_removed}\")\n",
    "print(f\"Rows remaining: {rows_remaining}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58108851-8a48-43f8-a88c-867730968302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
